### 事件图模式归纳

#### 定义：

***事件模式***（Event schema）**：**同一主题的事件通常具有相似的发展规律，这种规律称为事件模式（Event schema）。例如“袭击（Attack）”事件发生之后会引发“伤亡（Injuries）”事件，随后袭击发动者会遭到“逮捕（Arrest）”，从而形成“袭击→伤亡→逮捕的事件模式：。

**事件图模式**： two event types are connected through multiple paths involving entities that fifill important roles in a coherent story。假设当两个**事件**的**实体参数**是**共引用**的或**语义相关**的时，它们是相连的。两种事件类型通过包含实体-实体关系的路径连接起来。每个节点代表一个实体类型或事件类型，每条边代表一个实体-实体关系类型或在事件中扮演的实体的参数角色。

**事件图模式归纳**是根据**实例图**（instance graph）归纳出这些实例图的潜在逻辑模式、事件的潜在的**演化规则**。例如：从"张三→偷盗→手机"归纳出的schema为

"person→steal→item"。[1]**Connecting the Dots: Event Graph Schema Induction**

**with Path Language Modeling** 提出。

**有没有统一的定义**

知识图和事件图区别:知识图是以实体为中心的，由静态的实体-实体关系组成，而事件图是以事件为中心的和动态的，其中新的事件和实体可能会随着图的发展而出现。

#### Challenge:要解决的问题：

【1】以前的schema induction methods模式归纳方法大多忽略了不确定性、重新发生的事件和多种假设，除了时间或因果关系之外，对捕捉**事件之间的复杂关系**（它的复杂性来自于包含了多个原子事件（及其参数）、关系和时间顺序。复杂事件模式可以用来定义特定类型的复杂事件的典型结构）关注有限.

【2】以前关于事件模式归纳的工作将复杂事件视为原子事件的集合或线性序列，忽略了通过参数和参数关系的事件之间的相互作用。

复杂：一个事件的发生可能依赖于多个事件

【3】现有的基于图的方法仅限于建模事件图的局部结构.忽略整个图上原子事件的高阶和全局依赖。获取复杂事件的全局结构信息

#### 论文列表：

其中第一篇论文是该领域的开山之作，第二篇和第三篇论文是基于第一篇的工作继续推进的工作。论文[1]**基于路径语言模型的事件图模式归纳**路径语言模型学习实例图中的出现频率高的路径作为schema的组成部分，实现事件模式归纳；论文[2]**基于图生成模型的事件图模式归纳**设计了一种图生成结构模型，**同时实现了事件模式归纳与事件预测**，并在性能上取得了进一步提高；论文[3]**基于双图自编码器的事件图模式归纳**设计了一个双图自编码器，将schema induction拆分为两阶段的任务。

文章列表如下：[1]Connecting the dots: Event graph schema induction with path language modeling(**EMNLP**,**2020**)[2]Future is not one-dimensional: Graph modeling based complex event schema induction for event prediction (**EMNLP**, **2021**)[3]Event Schema Induction with Double Graph Autoencoder (**NAACL**, **2022**)

#### Motivation：

弄清楚事件演变背后的底层逻辑以及真实原因**（event schema）**

   **（1）**通过图结构来组织事件以及事件的论元角色，能够提高可解释性也能利用图神经网络的方法。

**（2）**通过**图神经网络**进行事件图模式推理（event graph schema induction），并将推理出的schema运用到事件预测当中。

**（3）**针对事件模式归纳这一任务，现有工作往往将研究的重心集中在单个事件本身与局部的事件相关性上，忽略了事件知识图谱中所有事件整体的**全局依赖信息**。本文使用图自编码器捕捉单个事件与事件知识图谱整体间的全局依赖性信息，提出了一种新的基于图自编码的事件模式归纳技术。

**（4）**除了事件之间的因果、时序关系，各个事件还可能有**相同的事件发起者或有相同的客体**，针对这种复杂事件的模式归纳，现有工作大多仍然将注意力集中于事件本身或事件间的直接连接，而忽略了事件之间**通过实体产生的关系**。

#### Task：

通过实例事件图（instance event graph）归纳出事件图模式，即**事件图模式归纳（event graph schema induction）**

如何将两个事件类型进行有效关联，即关联路径的选择问题（显著性 连贯性）

event graph complemention。 event prediction 有没有其他的应用？

#### Method：（提出什么方法解决什么问题 解决到什么程度/效果 共同点 不同点）

（1）路径语言模型（path language model）**,通过抽取**（OneIE工具）**重要(salient)以及连贯(coherent)的路径来构造schema。路径语言模型由两个部分构成：自回归语言模型、邻居分类模型。自回归语言模型用来处理**单条路径的出现频率以及语义连贯性（**自回归语言模型具有强大的schema构造能力**）给定路径中之前的边和节点，来预测一条边或节点**；邻居分类模型用来处理**多条路径是否同时出现在同一个schema中。事件图模式的生成则是对两个事件类型之间的所有路径进行排序，选取top k的路径进行融合从而生成新的事件图模式。核心有两个，一个是从文本转换为实例图。另一个是从合并事件模式路径，形成一个大的事件模式图。【不足：只考虑两个事件间的联系 事件预测任务设置为自动生成缺失事件或给定当前事件预测一个前条件事件】

（2）文中提出了一种**基于图神经网络的生成式模型**。通过现有的部分图谱，不断的生成新的结点和边。同时结合共指消解以及事件时序顺序预测，得到最终的schema。然后再进行schema-guided prediction【事件预测：利用自动发现的时间事件模式作为预测未来事件的指导。】

 Temporal Event Graph Model,一个自回归图生成模型。给定一个当前提取的事件图，生成下一个有潜在参数的事件类型节点，然后按照时间顺序传播边缘感知信息。此之后，使用一个复制机制来生成共指论元，并为它们构建关系边。最后，通过考虑参数连接来确定时间依赖关系。捕获了事件之间的时间依赖性和多跳参数依赖性

（3）为了归纳出EKG schema，文中首先对已有的instance graph进行抽取，得到event skeleton。接着将skeleton作为第一个**自回归编码器的输入**，输出就是重构的schema skeleton。再对得到的schema skeleton进行论元补全，将补全之后的skeleton输入到GCN当中，最后就可以得到完整的schema

（4）设计模型对**事件知识图谱进行补全**。输入实例级事件知识图谱I和对应的事件模式S，进行子图匹配后从匹配子图外的节点中选出候选节点，分别通过邻居模块（Neighbor module）和路径模块（Path module）对该候选节点应该加入图谱的置信度进行计算，置信度高于阈值则将该候选节点加入I中，否则不加入。

#### Experiment：

##### Dataset：

（1）ACE2005。在这个数据集上对四个baseline（frequency、unigram、bigram、trigram）进行了实验，并将结果和路径语言模型进行比较。

**（2）**两个针对不同场景的数据集（**general IED、IED**），分别对一般场景、特定场景下模型的性能进行了测试采用Event Language Model和Sequential Pattern Mining作为baseline，同时进行了消融实验，测试了本文所提出的Event Graph Model在不进行实体共指融合时性能有何变化。

(3)General-IED，Car-IED，Suicide-IED。

##### 评价指标：evaluation metrics

[1]instance coverage and instance coherence 实例的覆盖范围和实例的一致性

good path：(1).Salience:在两种事件类型中频繁出现(2)Coherence:同一对事件类型之间的多条路径应该连贯的故事，即它们应该经常同时出现在同一discourse中（document）

【2】**Schema Matching Evaluation**：1）Event Match 2）Event Sequence Match 3）Event Argument Connection Match  **Instance Graph Perplexity Evaluation**

【3】1）Event Match 2）Event Sequence Match 3）*Node/edge type distribution* 4）*Maximum common subgraph* (MCS) 反映两个图之间的全局结构相似性 计算模式和每个测试实例图之间的最大公共子图的节点数和边数。

##### baseline：

(1) **Frequency Ranking Model** (2) **Unigram, Bigram, and Trigram Language Models**

（2）**Event Language Model**     **Sequential Pattern Mining**

（3）Temporal Event Graph Model (TEGM)   *Frequency-Based Sampling* (FBS)：基于训练数据中的事件-事件时间链接的频率来构建事件模式

**效果**：

[1]**intrisic**: highly effective at inducing salient and coherent schemas. **extrisic:** 在下游的信息提取任务上（entity extraction, relation extraction, event extraction and argument role labeling），相比于sota joint neural extraction model有显著改进。

#### Related Work:

event schema

Atomic Event Schema Induction：单个原子事件的事件类型和参数角色 忽略事件间关系

Narrative Event Schema Induction. 使用动词 而事件图使用事件类型

schema induction and script learning.(忽略事件内部信息)

Path-based Language Model：学习路径中的节点表示 （本文incorporate latent linguis

tic structures into language models based on typed event-event paths.）

Graph Pattern Mining.（忽略了多个模式之间的语义一致性）

script learning：假设事件在单个链中遵循线性顺序 （本文诱导了一个全面的事件图模式，捕获了事件之间的时间依赖性和多跳参数依赖性。）

下游任务：event graph completion and event prediction

#### Future:哪些问题没有解决

extend graph schemas to encode hierarchical and temporal relations, as well as rich ontologies in open domain. 

【1】auto-matically decide the type granularity

【2】 extend graph schemas to encode hierarchical and temporal relations, as well as rich ontologies in open domain. 

【3】event and argument instance prediction

### 应用

【1】**Schema-Guided Event Graph Completion**;预测事件图中缺失的事件节点

现有方法;现有的link prediction或图补全方法很难处理事件图，因为它们通常是为单个大型图设计的，如社交网络或知识图，而不是多个小的动态事件图。此外，它们只能预测缺失的边，而不是缺失的节点

###### method:

首先通过启发式子图匹配算法将一个实例事件图映射到模式图的一个子图。问题等价于推断模式的匹配子图是否缺少候选节点。然后，通过描述模式图的两种局部拓扑类型：候选节点和子图的邻居，以及连接候选节点和子图的路径，来预测是否应该将模式图中的候选事件节点添加到实例化的模式子图中。然后将这两个模块组合在一起以进行最终的预测。

Dataset：*Car-Bombing*s, *IED-Bombings*, *Suicide-IED*, and *Pandemic*. 对四个事件实例图数据集用了三种复杂事件模式

Related work：相较于之前以学习事件模式为目标的工作，本文关注于事件模式的下游任务

Knowledge Graph Completion：许多知识图补全方法都是1）基于嵌入的，它通过最小化所有triplets上的预定义损失函数来学习每个实体和关系的嵌入向量。 2）基于规则的方法，其目的是通过建模the head and the tail实体之间的路径，从知识图中学习一般的逻辑规则。然而，这些方法的一个显著缺点是，有意义的规则通常是非常稀疏的，这限制了它们预测未被已知规则覆盖的缺失关系的能力。们的方法可以看作是结合了这两类方法的方法，但我们的方法是专门为事件图设计的。

Graph Matching：通过一个基于注意力的图神经网络来学习两个图之间的节点匹配关系。但是，他们的研究图和我们的研究图有很大的不同，因为事件图中的节点有类型信息，它们应该严格匹配，这将大大减少匹配空间。因此，我们提出的子图匹配算法充分利用了事件类型信息，比传统的或基于神经网络的方法运行得快得多。

future work：基于事件模式来细化事件图中的链接、利用事件层次结构来提高模型的性能。

【2】**Schema-guided Event Prediction** 新闻场景下

现有方法：利用complex event schemas 进行事件预测：缺乏高质量的、开放域信息提取系统来构建模式归纳所需的事件实例图，这些方法往往局限于少数场景

method：使用事件模式（ discovered at scale）来指导预测模型的学习。

1）模式库构建：我们首先确定了11个有新闻价值的场景，并通过自动模式归纳和手动管理的组合构建了全面的层次模式。

2）IE系统：开发了一个开放域端到端多媒体多语言信息提取系统，该系统基于一系列基于弱监督的方法，可以提取所有这些场景的实体、关系、事件和时间顺序，包括few-shot学习和lifelong学习。

3）我们开发了一种新的模式匹配和预测算法，它能够恢复缺失的事件，并预测未来可能发生的事件。

【3】**Timeline Summarization based on Event Graph Compression** **via Time-Aware Optimal Transport**

Timeline Summarization：从新闻集合中识别主要事件，并按照时间顺序描述它们，并标记关键日期。

现有方法：在确定事件的关键日期之后，分别为每个日期生成摘要。这些方法忽略了事件的内部结构（参数）和结构间（事件-事件连接）。预训练语言模型，如BERT和GPT-2，在处理输入文档大小的全局上下文时，在表示容量和内存效率方面都受到限制。

method：（事件图表示和压缩来处理全局图上下文化、可伸缩性和时间感知中的表示困难。）将新闻文章表示为一个事件图，摘要任务：将整个图压缩为其显著的子图。

**(1) Event graph construction for multi-doc encoding**

从输入文档构建一个单一的事件图。通过时间顺序连接事件

**(2) Unsupervised event graph compression with optimal transport (OT)**

提出了一个新的时间轴摘要公式，通过从输入图中选择事件节点来形成一个更小的摘要图。

约束了要保留在摘要中的事件节点的总数，并使用最优传输方法优化了摘要图，使其接近于原始图。训练目标是找到具有最小运输距离的输入图和汇总图之间的最优运输计划。

**(3) Time-aware Gromov-Wasserstein distance:**

两图之间距离：i) Semantic relevance：每个节点首先通过预先训练好的BERT模型和节点类型嵌入对其初始局部上下文进行编码。

ii)Structural centrality ：采用图神经网络，通过编码全局结构拓扑来保持全局上下文嵌入

  iii) Temporal coherence:我们定义了时间边缘上的时间感知格罗莫夫瓦瑟斯坦距离，并引入了一个时间正则化器来扩大具有较宽时间间隔的事件之间的距离，从而可以捕获时间相干性。它使模型能够选择具有时间依赖性的时间显著事件

